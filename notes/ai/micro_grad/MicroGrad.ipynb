{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce5c686c-107a-4f76-8c14-953abe0d11ec",
   "metadata": {},
   "source": [
    "# Micrograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5850e2-54bc-4727-bc4e-da0c954384ef",
   "metadata": {},
   "source": [
    "Micrograd is a small library made by Andrej Karpathy. This is a reimplementation made by me.\n",
    "I wanted to have a version of Micrograd with a ton of documentation after watching the amazing\n",
    "video made possible by Adrej that [you can view here](https://www.youtube.com/watch?v=VMj-3S1tku0).\n",
    "\n",
    "The code is licensed under the MIT license and you can use it for whatever you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73680d3c-811e-413f-9654-e3ea2e22739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525a8d7-135b-46a7-9666-29514413a3d3",
   "metadata": {},
   "source": [
    "# We have to create a datastructure (The Engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce9fa6-6aee-468b-971c-fcaf6452cd40",
   "metadata": {},
   "source": [
    "Creating a new datastructure so our life is easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0329db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    def __init__(self, value):\n",
    "        # Create a constructor for the datastructure\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19bb6b8",
   "metadata": {},
   "source": [
    "We are going to add a bit more. We are going to make it able to add between the Tensor type and a constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87083d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    def __init__(self, value):\n",
    "        # Create a constructor for the datastructure\n",
    "        self.value = value\n",
    "    def __add__(self, other): \n",
    "        # self + other\n",
    "        return Tensor(self.value + other.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd59cc8",
   "metadata": {},
   "source": [
    "That seems like enough for now. Now we should check what is a gradient.\n",
    "\n",
    "The gradient is a small step forward in the direction of our derivative.\n",
    "\n",
    "But we should have a way to store this information. So we should add this to our class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192116cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    def __init__(self, value):\n",
    "        # Create a constructor for the datastructure\n",
    "        self.value = value\n",
    "        self.grad = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde67136",
   "metadata": {},
   "source": [
    "And now that we have the possiblity to have a gradient, we should look back at what calculus is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c4902",
   "metadata": {},
   "source": [
    "# Looking at you Calculus!\n",
    "\n",
    "So we need can look at the definition of a derivative\n",
    "\n",
    "$$x = \\lim_{\\Delta x \\rightarrow 0} \\frac{f(a+\\Delta x)-f(a)}{\\Delta x}$$\n",
    "\n",
    "This did not tell me anything at first. So let's do an example.\n",
    "\n",
    "For example. If we have a value $a = 3.0$ and a value $b=0.5$ we can get their derivatives with respect to each other.\n",
    "\n",
    "So we can see the derivatives with respect to each other if we add them. We are going to name the result of this operation $c$\n",
    "\n",
    "$$c = a+b$$\n",
    "\n",
    "And now we can get the derivative with respect to $a$ and the derivative with respect to $b$.\n",
    "\n",
    "So we are going to do a _limit_. This might seem scary but what the thing above is telling us is just to add a really small amount to see if it works.\n",
    "\n",
    "So we are going to say: $\\Delta x = 0.0001$\n",
    "\n",
    "We have our $c1$ that is the value of $3.5$ and we increment the value of a by $0.0001$ so we get $c2 = 3.0001 + 0.5 = 3.5001$ and we can evaluate this value in\n",
    "the derivative:\n",
    "\n",
    "$$\\frac{c2-c1}{\\Delta x} = \\frac{ 3.5001-3.5}{0.0001} = \\frac{0.0001}{0.0001} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3943005-d0b5-42a9-968f-91c08913d587",
   "metadata": {},
   "source": [
    "Now we can do the same but for other operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc0fd75-4178-4373-83a7-67a54f59ed3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 3.0\n",
    "b = 1.5\n",
    "h = 0.0001\n",
    "\n",
    "c1 = a*b\n",
    "c1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382dd97-3e26-4d1c-91ac-f396d40e6cbf",
   "metadata": {},
   "source": [
    "We can see the difference in the slope by going through the same process we did with the adition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ac241e-f82e-4bae-aa35-278db40e6f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.500000000005386"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a += h\n",
    "b = 1.5\n",
    "\n",
    "c2 = a*b\n",
    "derivative = (c2-c1)/h\n",
    "derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2b88f9-f688-4933-af36-b4fe4c595e4b",
   "metadata": {},
   "source": [
    "And for the derivative of b with respect to a we can see the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd81973-501c-4175-9bdb-413aa665d3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.00000000000189"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 3.0\n",
    "b = 1.5\n",
    "h = 0.0001\n",
    "\n",
    "c1 = a*b\n",
    "b += h\n",
    "c2 = a*b\n",
    "\n",
    "(c2-c1)/h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85a8527-b677-407c-ad27-4791a4ab4ee1",
   "metadata": {},
   "source": [
    "We can see that the values of the derivatives for $a$ and $b$ swap in the derivative. \n",
    "So we can modify our Tensor class to store the gradients of this operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e575c5-6dfb-48c5-b7c4-1a3a369db0a5",
   "metadata": {},
   "source": [
    "# The Full Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7590be-27b7-46c1-9a07-b8bc91cb0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    \"\"\"\n",
    "        Stores a single value.\n",
    "    \"\"\"\n",
    "    def __init__(self, value, _children=(), _operation=\"\"):\n",
    "        # Create a constructor for the datastructure\n",
    "        self.value = value\n",
    "        self.gradient = 0.0\n",
    "        \n",
    "        # Internal variables\n",
    "        self._prev = set(_children)\n",
    "        self._backward = lambda: None\n",
    "        \n",
    "        # Debugging\n",
    "        self._operation = _operation\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        # self + other\n",
    "        other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "        output = Tensor(self.value + other.value, (self, other), '+')\n",
    "        \n",
    "        def _backward():\n",
    "            self.gradient += output.gradient\n",
    "            other.gradient += output.gradient\n",
    "        output._backward = _backward\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        # self * other\n",
    "        other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "        output = Tensor(self.value * other.value, (self, other), '*')\n",
    "        \n",
    "        def _backward():\n",
    "            # we use the chain rule so that is why we multiply out.gradient * self and out.grad * other.value\n",
    "            self.gradient += other.value * output.gradient\n",
    "            other.gradient += self.value * output.gradient\n",
    "        output._backward = _backward\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return self * other\n",
    "    \n",
    "    def __pow__(self, other):\n",
    "        # self ** other\n",
    "        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
    "        output = Tensor(self.value ** other, (self,), '^')\n",
    "        \n",
    "        def _backward():\n",
    "            self.gradient += (other*self.value ** (other-1))*output.gradient\n",
    "        \n",
    "        output._backward = _backward\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backward(self):\n",
    "        # Topological order of the children in the graph\n",
    "        # Using the dfs version of topological sort\n",
    "        topological_order = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topological_order.append(v)\n",
    "        \n",
    "        build_topo(self)\n",
    "        \n",
    "        self.gradient = 1.0\n",
    "        \n",
    "        for v in reversed(topological_order):\n",
    "            v._backward()\n",
    "    \n",
    "    def __neg__(self):\n",
    "        return self*-1\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return self + (-other)\n",
    "    \n",
    "    def __rsub__(self, other):\n",
    "        return other + (-self)\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        return self * other**-1\n",
    "    \n",
    "    def __rtruediv__(self, other):\n",
    "        return other * self**-1\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # This function returns the value formatted when you print it in jupyterlab\n",
    "        return f\"Tensor=({self.value}, gradient={self.gradient})\"\n",
    "    \n",
    "    # Extra\n",
    "    def tanh(self):\n",
    "        x = self.value\n",
    "        t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n",
    "        out = Tensor(t, (self, ), 'tanh')\n",
    "\n",
    "        def _backward(): \n",
    "            self.gradient += (1 - t**2) * out.gradient\n",
    "        \n",
    "        out._backward = _backward\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96adbc56-3a65-4910-85d3-672bd4c0487a",
   "metadata": {},
   "source": [
    "# The nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c91e2e4-7a02-4306-8bf6-cbdff0e430c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters():\n",
    "            p.gradient = 0\n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d61edb78-6ef0-4de1-b56b-0e1b19479990",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \"\"\" Class Neuron inherits from Module \"\"\"\n",
    "    \n",
    "    def __init__(self, nin):\n",
    "        # Initialize number in neuron\n",
    "        # Nin --> Number of inputs\n",
    "        self.w = [Tensor(random.uniform(-1,1)) for _ in range(nin)]\n",
    "        self.b = Tensor(0)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # w * x +b\n",
    "        act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b)\n",
    "        out = act.tanh()\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55e42b33-6547-4b7d-9366-402d0801a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, nin, nout):\n",
    "        self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        outs = [n(x) for n in self.neurons]\n",
    "        return outs[0] if len(outs) == 1 else outs\n",
    "    def parameters(self):\n",
    "        \n",
    "        params = []\n",
    "        for neuron in self.neurons:\n",
    "            ps = neuron.parameters()\n",
    "            params.extend(ps)\n",
    "            \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "935bfb28-de0c-49d6-8b1f-e31e4942f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    \"\"\"\n",
    "        Multi-Layer Perceptron\n",
    "    \"\"\"\n",
    "    def __init__(self, nin, nouts):\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83dd8ec-2133-4691-84ab-fb885a00ea6f",
   "metadata": {},
   "source": [
    "# An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3169d539-4115-477f-b929-88faa2bec85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor=(-0.1287955604443376, gradient=0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [2.0, 3.0, -1.0]\n",
    "n = MLP(3, [4,4,1])\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a72ad317-39a1-478c-b559-80041f8dba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0]\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0] # desired targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2065b6d0-c49a-40bf-9898-6b5c1f032810",
   "metadata": {},
   "source": [
    "Creating a metric function. In this case we use the mean squared error function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a21d6d-8557-48ab-9517-fc220078c152",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c97711e9-e48b-41ff-9480-578ae537df63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.6461118424965435\n",
      "1 2.1992116474110746\n",
      "2 1.527268058818012\n",
      "3 0.8253180411028479\n",
      "4 0.40729347993046133\n",
      "5 0.24480034340777723\n",
      "6 0.17218984478699947\n",
      "7 0.13184120295831725\n",
      "8 0.1061546958093535\n",
      "9 0.08847664212460303\n",
      "10 0.07562214221526461\n",
      "11 0.06588452062362513\n",
      "12 0.05827078639381458\n",
      "13 0.052165700093168815\n",
      "14 0.047168659872599494\n",
      "15 0.04300810479948695\n",
      "16 0.039493711891586084\n",
      "17 0.0364883006996128\n",
      "18 0.033890600113030425\n",
      "19 0.03162428737994592\n"
     ]
    }
   ],
   "source": [
    "for k in range(20):\n",
    "    # forward pass\n",
    "    ypred = [n(x) for x in xs]\n",
    "    loss = sum((yout-ygt)**2 for ygt, yout in zip(ys, ypred))\n",
    "\n",
    "    \n",
    "    # zero grad\n",
    "    for p in n.parameters():\n",
    "        p.gradient = 0.0\n",
    "        \n",
    "    # backward pass    \n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    for p in n.parameters():\n",
    "        p.value += -0.05*p.gradient\n",
    "    \n",
    "    print(k, loss.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7dfbf35-ec0d-49b0-8a8f-d35d89b34edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tensor=(0.9376107822235494, gradient=-0.12477843555290113),\n",
       " Tensor=(-0.9612476093889457, gradient=0.07750478122210858),\n",
       " Tensor=(-0.88266676867396, gradient=0.23466646265208002),\n",
       " Tensor=(0.8883620228877879, gradient=-0.22327595422442426)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88895fd1-fa20-426b-a201-cb8e6ccaf1ac",
   "metadata": {},
   "source": [
    "We almost got the predictions we wanted! That is really cool (do not look at the concept of overfitting obiously)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ebd62e-7e37-468b-bb2a-285d5de8a306",
   "metadata": {},
   "source": [
    "# A bigger example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e4f40e-60ee-41fa-ab02-4d152e9f0039",
   "metadata": {},
   "source": [
    "**TODO**: Actually make this work. I went through the demo they have in micrograd. But wanted to implement something else. So This is the general structure but it has a lot of bugs.\n",
    "\n",
    "I wanted to use the iris dataset as a bigger example than the one given in the class. I think it is relatively simple to classify and at the same time it is really visually apparent in the way it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98cebd45-47b2-46b1-99ce-017c2d14a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff26e8cb-12b6-4f69-92dd-498e7a5aa022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/anaconda3/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Graph the data\n",
    "sns.scatterplot(X[:,0], X[:,2], hue=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e569525e-5392-4bd2-b051-31dadf468b1f",
   "metadata": {},
   "source": [
    "Create a Multi layer perceptron of two layers of ten neurons each and a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "364b5809-0b26-4148-98e2-9243506c89b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 151\n"
     ]
    }
   ],
   "source": [
    "model = MLP(2, [10, 10, 1])\n",
    "print(\"Number of parameters:\", len(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "518c214c-2896-4f95-9a5e-003cf1faf09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor=(1062.0059237090663, gradient=0.0)\n"
     ]
    }
   ],
   "source": [
    "def loss(batch_size=None):\n",
    "    \n",
    "    if batch_size is None:\n",
    "        Xb, yb = X, y\n",
    "    else:\n",
    "        ri = np.random.permutation(X.shape[0])[:batch_size]\n",
    "        Xb, yb = X[ri], y[ri]\n",
    "    inputs = [list(map(Tensor, xrow)) for xrow in Xb]\n",
    "    \n",
    "    # get scores\n",
    "    scores = list(map(model, inputs))\n",
    "    \n",
    "    # We are scoring based on mse\n",
    "    current_loss = sum((scorei-yi)**2 for yi, scorei in zip(yb, scores))\n",
    "    \n",
    "    # L2 regularization\n",
    "    alpha = 1e-4\n",
    "    reg_loss = alpha * sum((p*p for p in model.parameters()))\n",
    "    \n",
    "    return current_loss\n",
    "current_loss = loss()\n",
    "print(current_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88bdf669-6343-466d-b366-251a20c4e663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 1062.0059237090663\n",
      "step 10 loss 212.0\n",
      "step 20 loss 212.0\n",
      "step 30 loss 212.0\n",
      "step 40 loss 212.0\n",
      "step 50 loss 212.0\n",
      "step 60 loss 212.0\n",
      "step 70 loss 212.0\n",
      "step 80 loss 212.0\n",
      "step 90 loss 212.0\n"
     ]
    }
   ],
   "source": [
    "# Optimization\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    current_loss = loss()\n",
    "    \n",
    "    # zero grad\n",
    "    for p in model.parameters():\n",
    "        p.gradient = 0.0\n",
    "        \n",
    "    # backward pass    \n",
    "    current_loss.backward()\n",
    "    \n",
    "    # update Stochastic Gradient descent\n",
    "    learning_rate = 0.01 # maybe change to other thing later\n",
    "    for p in model.parameters():\n",
    "        p.value -= learning_rate*p.gradient\n",
    "    \n",
    "    if k%10 == 0:\n",
    "        print(f\"step {k} loss {current_loss.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c7417f4-429b-4ff0-ac48-a1eb199b5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [list(map(Tensor, xrow)) for xrow in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8601c9e2-f459-4d43-88db-9ad4dbeceb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = list(map(model, inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bb16b4b-49dc-4c45-aa2e-2a9586a67380",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [pred.value for pred in preds]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
